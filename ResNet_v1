import os
import time
from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, BatchNormalization, AveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras import layers



# RES NET FUNCTION DEFINITIONS
def resnet_layer(inputs,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 activation='relu',
                 batch_normalization=True,
                 conv_first=True):

    conv = Conv2D(num_filters,
                  kernel_size=kernel_size,
                  strides=strides,
                  padding='same',
                  kernel_initializer='he_normal',
                  kernel_regularizer=regularizers.l2(1e-4))

    x = inputs
    if conv_first:
        x = conv(x)
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
    else:
        if batch_normalization:
            x = BatchNormalization()(x)
        if activation is not None:
            x = Activation(activation)(x)
        x = conv(x)
    return x

# RESNET ARCHITECTURE
def resnet_v1(input_shape, depth, num_classes=1):
    if (depth - 2) % 6 != 0:
        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')
    # Start model definition.
    num_filters = 16
    num_res_blocks = int((depth - 2) / 6)

    inputs = layers.Input(shape=input_shape)
    x = resnet_layer(inputs=inputs)
    # Instantiate the stack of residual units
    for stack in range(3):
        for res_block in range(num_res_blocks):
            strides = 1
            # first layer but not first stack
            if stack > 0 and res_block == 0:  
                strides = 2  # downsample
            y = resnet_layer(inputs=x,
                             num_filters=num_filters,
                             strides=strides)
            y = resnet_layer(inputs=y,
                             num_filters=num_filters,
                             activation=None)
            # first layer but not first stack
            if stack > 0 and res_block == 0:  
                # linear projection residual shortcut connection to match
                # changed dims
                x = resnet_layer(inputs=x,
                                 num_filters=num_filters,
                                 kernel_size=1,
                                 strides=strides,
                                 activation=None,
                                 batch_normalization=False)
            x = layers.add([x, y])
            x = Activation('relu')(x)
        num_filters *= 2

    # Add classifier on top.
    # v1 does not use BN after last shortcut connection-ReLU
    x = AveragePooling2D(pool_size=8)(x)
    y = Flatten()(x)
    outputs = Dense(num_classes, activation='sigmoid', kernel_initializer='he_normal')(y)

    # Instantiate model.
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])
    return model


# scan directory containing train and test subdirs for each class (acute intracranial bleed and no acute intracranial bleed)
abs_processed = '~/scans'

earlystop = EarlyStopping(patience = 3, monitor='val_loss', restore_best_weights=True)
learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.5, min_lr = 1e-8)
callbacks = [earlystop, learning_rate_reduction]

# image parameters
Image_Width=128
Image_Height=128
Image_Channels = 3

DEPTH = Image_Channels * 6 + 2

Image_Size=(Image_Width, Image_Height)
input_shape = shape=(Image_Width, Image_Height, Image_Channels)

# define size of train and validation sets
total_train = len(os.listdir(os.path.join(abs_processed, 'train', 'bleed'))) + len(os.listdir(os.path.join(abs_processed, 'train', 'normal')))
total_validate = len(os.listdir(os.path.join(abs_processed, 'test', 'bleed'))) + len(os.listdir(os.path.join(abs_processed, 'test', 'normal')))

batch_size= 2**7
epochs = 2
l2_reg = 1e-4

# define generators
train_datagen = ImageDataGenerator(
    rotation_range=60, 
    rescale=1/255.0,
    zoom_range=0.3,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    brightness_range=[0.2,1.8],
    fill_mode="nearest",
)
train_generator = train_datagen.flow_from_directory(os.path.join(abs_processed, 'train'),
    target_size=Image_Size,
    class_mode='binary',
    batch_size=batch_size,
    color_mode="rgb"
)

validation_datagen = ImageDataGenerator(rescale=1/255.0)
validation_generator = validation_datagen.flow_from_directory(os.path.join(abs_processed, 'test'),
    target_size=Image_Size,
    class_mode='binary',
    batch_size=batch_size,
    color_mode='rgb'
)

def run(DEPTH, input_shape):
    model = resnet_v1(input_shape=input_shape, depth=DEPTH)
    model.summary()
    time.sleep(2)

    model.fit_generator(
        train_generator, 
        epochs=epochs,
        steps_per_epoch=total_train//batch_size,
        validation_data=validation_generator,
        validation_steps=total_validate//batch_size,
        callbacks=callbacks,
        verbose=1
    )

    # list of val loss, val acc, val auc
    scores = model.evaluate_generator(
        validation_generator,
        total_validate//batch_size,
    )

    print(f'the scores are in: {scores}\n')



gpu_t = tf.test.is_built_with_cuda()
print(f'****************************\n GPU Available: {gpu_t}\n****************************')

# entry point
run(DEPTH, input_shape)
